// app/page.tsx
"use client";

import React, { useEffect, useRef, useState } from "react";
import { santaSystemPrompt } from "@/lib/santaPrompt";

type LogLine = { t: number; text: string };

export default function Home() {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioTxRef = useRef<RTCRtpTransceiver | null>(null);

  const [started, setStarted] = useState(false);
  const [logs, setLogs] = useState<LogLine[]>([]);
  const [voice, setVoice] = useState("ash");
  const [model, setModel] = useState("gpt-realtime");
  const [micDeviceId, setMicDeviceId] = useState<string | undefined>(undefined);
  const [mics, setMics] = useState<MediaDeviceInfo[]>([]);
  const [isTalking, setIsTalking] = useState(false);

  function log(text: string) {
    setLogs((prev) => [...prev, { t: Date.now(), text }]);
  }

  useEffect(() => {
    navigator.mediaDevices.enumerateDevices().then((devices) => {
      setMics(devices.filter((d) => d.kind === "audioinput"));
    });
  }, []);

  async function startCall() {
    if (started) return;

    log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC‚Ä¶");

    const pc = new RTCPeerConnection({
      iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }],
    });
    pcRef.current = pc;

    // –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    pc.addEventListener("iceconnectionstatechange", () => log("ICE state: " + pc.iceConnectionState));
    pc.addEventListener("connectionstatechange", () => log("PC state: " + pc.connectionState));

    // –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å–Ω–∏–º–∞–µ–º mute –∏ –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
    if (audioRef.current) {
      audioRef.current.muted = false;
      audioRef.current.volume = 1.0;
    }

    // –†–µ–Ω–¥–µ—Ä —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ: –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∏–º–µ–Ω–Ω–æ track
    pc.ontrack = (event) => {
      const track = event.track;
      log(`remote track: kind=${track.kind} id=${track.id} streams=${event.streams.map(s => s.id).join(",")}`);
      if (track.kind === "audio") {
        const ms = new MediaStream();
        ms.addTrack(track);
        if (audioRef.current) {
          audioRef.current.srcObject = ms;
          audioRef.current.muted = false;
          audioRef.current.volume = 1.0;
          audioRef.current.play().catch((e) => log("audio.play() blocked: " + String(e)));
        }
      }
    };

    // DataChannel –¥–ª—è –∫–æ–º–∞–Ω–¥/–ª–æ–≥–æ–≤
    const dc = pc.createDataChannel("santa-data");
    dcRef.current = dc;

    dc.onopen = () => {
      // (1) –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –î–û –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–∫–ª—é—á–µ–Ω–∞
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          instructions: santaSystemPrompt,
          voice,
          modalities: ["audio", "text"],
          turn_detection: { type: "server_vad", create_response: false, interrupt_response: true },
        },
      }));

      // (2) –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
      dc.send(JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          instructions: "–°–∫–∞–∂–∏ –≥–æ–ª–æ—Å–æ–º –°–∞–Ω—Ç–∞ –ö–ª–∞—É—Å–∞ '–•–æ-—Ö–æ-—Ö–æ, –Ø –°–∞–Ω—Ç–∞ –ö–ª–∞—É—Å, –∞ –∫–∞–∫ –∑–æ–≤—É—Ç —Ç–µ–±—è?'",
        },
      }));

      // (3) –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—ã
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          turn_detection: { type: "server_vad", create_response: true, interrupt_response: true },
        },
      }));

      // (4) –ü–æ–¥–∫–ª—é—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω (replaceTrack)
      attachMic().catch((e) => log("–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: " + String(e)));
    };

    dc.onmessage = (e) => log(`DC: ${e.data}`);

    // === –ú–µ–¥–∏–∞—Å–µ–∫—Ü–∏–∏ –≤ SDP –î–û createOffer ===
    // –ê—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä: sendrecv (–ø–æ–∑–∂–µ –ø–æ–¥—Å—Ç–∞–≤–∏–º —Ä–µ–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫)
    audioTxRef.current = pc.addTransceiver("audio", { direction: "sendrecv" });

    // –í–∏–¥–µ–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä: recvonly (—Ç—Ä–µ–±—É–µ—Ç—Å—è Realtime)
    pc.addTransceiver("video", { direction: "recvonly" });

    // –°–æ–∑–¥–∞—ë–º –æ—Ñ—Ñ–µ—Ä, –∂–¥—ë–º ICE
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    await waitForIceGatheringComplete(pc);

    // –û–±–º–µ–Ω SDP —á–µ—Ä–µ–∑ –Ω–∞—à —Å–µ—Ä–≤–µ—Ä
    const resp = await fetch("/api/sdp", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        sdp: pc.localDescription?.sdp,
        voice,
        model, // —Å–µ—Ä–≤–µ—Ä –º–æ–∂–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π id
      }),
    });

    if (!resp.ok) {
      const err = await resp.json().catch(() => ({}));
      log(`–û—à–∏–±–∫–∞ SDP: ${JSON.stringify(err, null, 2)}`);
      return;
    }

    const answerSdp = await resp.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

    setStarted(true);
    log("–ì–æ—Ç–æ–≤–æ! –ì–æ–≤–æ—Ä–∏ —Å –î–µ–¥–æ–º –ú–æ—Ä–æ–∑–æ–º üéÖ");

    // –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥–æ–±–∏–≤–∞–µ–º –∞–≤—Ç–æ–ø–ª–µ–π
    audioRef.current?.play().catch((e) => log("autoplay retry: " + String(e)));
  }

  async function attachMic() {
    const pc = pcRef.current!;
    const constraints: MediaStreamConstraints = {
      audio: {
        deviceId: micDeviceId ? { exact: micDeviceId } : undefined,
        channelCount: 1,
        noiseSuppression: true,
        echoCancellation: true,
        autoGainControl: true,
      },
    };
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    const [track] = stream.getAudioTracks();

    // –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –≤ —É–∂–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä
    await audioTxRef.current?.sender.replaceTrack(track);

    // –ü—Ä–æ—Å—Ç–æ–π VAD-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä (UX)
    setupSimpleVAD(stream, (talking) => {
      setIsTalking(talking);
      const audio = audioRef.current;
      if (audio) audio.volume = talking ? 0.6 : 1.0; // –ø–æ–º—è–≥—á–µ –ø—Ä–∏–≥–ª—É—à–∞–µ–º
    });
  }

  function hangup() {
    dcRef.current?.close();
    pcRef.current?.getSenders().forEach((s) => s.track?.stop());
    pcRef.current?.close();
    pcRef.current = null;
    setStarted(false);
    log("–ó–≤–æ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.");
  }

  return (
      <main className="min-h-screen p-6 mx-auto max-w-2xl">
        <h1 className="text-2xl font-bold mb-4">–î–µ–¥ –ú–æ—Ä–æ–∑ ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∑–≤–æ–Ω–æ–∫ (MVP)</h1>

        <div className="space-y-3 mb-6">
          <div>
            <label className="block text-sm font-medium mb-1">–ú–∏–∫—Ä–æ—Ñ–æ–Ω</label>
            <select
                className="border rounded p-2 w-full"
                value={micDeviceId || ""}
                onChange={(e) => setMicDeviceId(e.target.value || undefined)}
                disabled={started}
            >
              <option value="">–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é</option>
              {mics.map((d) => (
                  <option key={d.deviceId} value={d.deviceId}>
                    {d.label || d.deviceId}
                  </option>
              ))}
            </select>
          </div>

          <div className="grid grid-cols-2 gap-3">
            <div>
              <label className="block text-sm font-medium mb-1">–ì–æ–ª–æ—Å</label>
              <select
                  className="border rounded p-2 w-full"
                  value={voice}
                  onChange={(e) => setVoice(e.target.value)}
                  disabled={started}
              >
                <option value="alloy">Alloy</option>
                <option value="ash">Ash</option>
                <option value="verse">Verse</option>
                <option value="cove">Cove</option>
              </select>
            </div>
            <div>
              <label className="block text-sm font-medium mb-1">–ú–æ–¥–µ–ª—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)</label>
              <input
                  className="border rounded p-2 w-full"
                  value={model}
                  onChange={(e) => setModel(e.target.value)}
                  disabled={started}
              />
              <p className="text-xs text-gray-500 mt-1">
                –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ –º–æ–∂–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω—ã–π id, –Ω–∞–ø—Ä–∏–º–µ—Ä: <code>gpt-4o-realtime-preview-2025-06-03</code>
              </p>
            </div>
          </div>

          <div className="flex items-center gap-3">
            {!started ? (
                <button onClick={startCall} className="px-4 py-2 rounded bg-blue-600 text-white">
                  –ü–æ–∑–≤–æ–Ω–∏—Ç—å –î–µ–¥—É –ú–æ—Ä–æ–∑—É
                </button>
            ) : (
                <button onClick={hangup} className="px-4 py-2 rounded bg-gray-700 text-white">
                  –ó–∞–≤–µ—Ä—à–∏—Ç—å
                </button>
            )}
            <div className={`text-sm px-2 py-1 rounded ${isTalking ? "bg-green-200" : "bg-gray-200"}`}>
              {isTalking ? "–í—ã –≥–æ–≤–æ—Ä–∏—Ç–µ‚Ä¶" : "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∂–¥—ë—Ç"}
            </div>
          </div>
        </div>

        <audio ref={audioRef} autoPlay playsInline />

        <div className="mt-6">
          <h2 className="font-semibold mb-2">–õ–æ–≥</h2>
          <div className="h-56 overflow-auto border rounded p-2 text-sm bg-white">
            {logs.map((l, i) => (
                <div key={i} className="whitespace-pre-wrap">
                  {new Date(l.t).toLocaleTimeString()} ‚Äî {l.text}
                </div>
            ))}
          </div>
        </div>
      </main>
  );
}

/** –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ICE-—Å–±–æ—Ä–∫–∏, —á—Ç–æ–±—ã SDP –≤–∫–ª—é—á–∞–ª –∫–∞–Ω–¥–∏–¥–∞—Ç—ã */
async function waitForIceGatheringComplete(pc: RTCPeerConnection) {
  if (pc.iceGatheringState === "complete") return;
  await new Promise<void>((resolve) => {
    function check() {
      if (pc.iceGatheringState === "complete") {
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    }
    pc.addEventListener("icegatheringstatechange", check);
  });
}

/**
 * –ü—Ä–æ—Å—Ç–µ–π—à–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è RMS ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏/UX.
 * –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –±–∞—Ä–¥–∂-–∏–Ω–∞ –æ–ø–∏—Ä–∞–µ–º—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–Ω—É—é VAD Realtime.
 */
function setupSimpleVAD(stream: MediaStream, onState: (talking: boolean) => void) {
  const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
  const ctx = new AudioCtx();
  const src = ctx.createMediaStreamSource(stream);
  const analyser = ctx.createAnalyser();
  analyser.fftSize = 1024;
  src.connect(analyser);
  const data = new Uint8Array(analyser.fftSize);

  let talking = false;
  function tick() {
    analyser.getByteTimeDomainData(data);
    let sum = 0;
    for (let i = 0; i < data.length; i++) {
      const v = (data[i] - 128) / 128;
      sum += v * v;
    }
    const rms = Math.sqrt(sum / data.length);
    const nowTalking = rms > 0.03; // –ø—Ä–æ—Å—Ç–æ–π –ø–æ—Ä–æ–≥
    if (nowTalking !== talking) {
      talking = nowTalking;
      onState(talking);
    }
    requestAnimationFrame(tick);
  }
  tick();
}
