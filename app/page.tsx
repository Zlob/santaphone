// app/page.tsx
"use client";

import React, { useEffect, useRef, useState } from "react";
import Image from "next/image";
import { santaSystemPrompt } from "@/lib/santaPrompt";

type LogLine = { t: number; text: string };

// –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
const DEFAULT_MODEL = "gpt-realtime";
const DEFAULT_VOICE = "ash";

export default function Home() {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const audioTxRef = useRef<RTCRtpTransceiver | null>(null);

  const [started, setStarted] = useState(false);
  const [logs, setLogs] = useState<LogLine[]>([]);
  const [showLogs, setShowLogs] = useState(false);
  const [isTalking, setIsTalking] = useState(false);

  function log(text: string) {
    setLogs((prev) => [...prev, { t: Date.now(), text }]);
  }

  async function startCall() {
    if (started) return;

    log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC‚Ä¶");

    const pc = new RTCPeerConnection({
      iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }],
    });
    pcRef.current = pc;

    // –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    pc.addEventListener("iceconnectionstatechange", () => log("ICE state: " + pc.iceConnectionState));
    pc.addEventListener("connectionstatechange", () => log("PC state: " + pc.connectionState));

    // –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å–Ω–∏–º–∞–µ–º mute –∏ –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
    if (audioRef.current) {
      audioRef.current.muted = false;
      audioRef.current.volume = 1.0;
    }

    // –†–µ–Ω–¥–µ—Ä —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –ø–æ –≤—Ö–æ–¥—è—â–µ–º—É —Ç—Ä–µ–∫—É
    pc.ontrack = (event) => {
      const track = event.track;
      log(`remote track: kind=${track.kind} id=${track.id} streams=${event.streams.map((s) => s.id).join(",")}`);
      if (track.kind === "audio") {
        const ms = new MediaStream();
        ms.addTrack(track);
        if (audioRef.current) {
          audioRef.current.srcObject = ms;
          audioRef.current.muted = false;
          audioRef.current.volume = 1.0;
          audioRef.current.play().catch((e) => log("audio.play() blocked: " + String(e)));
        }
      }
    };

    // DataChannel –¥–ª—è –∫–æ–º–∞–Ω–¥/–ª–æ–≥–æ–≤
    const dc = pc.createDataChannel("santa-data");
    dcRef.current = dc;

    dc.onopen = () => {
      // (1) –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –î–û –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, —Å–Ω–∞—á–∞–ª–∞ –±–µ–∑ –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç–∞
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          instructions: santaSystemPrompt,
          voice: DEFAULT_VOICE,
          modalities: ["audio", "text"],
          turn_detection: { type: "server_vad", create_response: false, interrupt_response: true },
        },
      }));

      // (2) –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
      dc.send(JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
          instructions: "–°–∫–∞–∂–∏ –≥–æ–ª–æ—Å–æ–º –°–∞–Ω—Ç–∞ –ö–ª–∞—É—Å–∞ '–•–æ-—Ö–æ-—Ö–æ, –Ø –°–∞–Ω—Ç–∞ –ö–ª–∞—É—Å, –∞ –∫–∞–∫ –∑–æ–≤—É—Ç —Ç–µ–±—è?'",
        },
      }));

      // (3) –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—ã –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          turn_detection: { type: "server_vad", create_response: true, interrupt_response: true },
        },
      }));

      // (4) –ü–æ–¥–∫–ª—é—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω (replaceTrack)
      attachMic().catch((e) => log("–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: " + String(e)));
    };

    dc.onmessage = (e) => log(`DC: ${e.data}`);

    // === –ú–µ–¥–∏–∞—Å–µ–∫—Ü–∏–∏ –≤ SDP –î–û createOffer ===
    // –ê—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä: sendrecv (—Ä–µ–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –ø–æ–¥—Å—Ç–∞–≤–∏–º –ø–æ–∑–∂–µ)
    audioTxRef.current = pc.addTransceiver("audio", { direction: "sendrecv" });
    // –í–∏–¥–µ–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä: recvonly ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è Realtime
    pc.addTransceiver("video", { direction: "recvonly" });

    // –°–æ–∑–¥–∞—ë–º –æ—Ñ—Ñ–µ—Ä, –∂–¥—ë–º ICE
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    await waitForIceGatheringComplete(pc);

    // –û–±–º–µ–Ω SDP —á–µ—Ä–µ–∑ –Ω–∞—à —Å–µ—Ä–≤–µ—Ä
    const resp = await fetch("/api/sdp", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        sdp: pc.localDescription?.sdp,
        voice: DEFAULT_VOICE,
        model: DEFAULT_MODEL, // –∑–∞—à–∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –º–æ–¥–µ–ª—å
      }),
    });

    if (!resp.ok) {
      const err = await resp.json().catch(() => ({}));
      log(`–û—à–∏–±–∫–∞ SDP: ${JSON.stringify(err, null, 2)}`);
      return;
    }

    const answerSdp = await resp.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

    setStarted(true);
    log("–ì–æ—Ç–æ–≤–æ! –ì–æ–≤–æ—Ä–∏ —Å –î–µ–¥–æ–º –ú–æ—Ä–æ–∑–æ–º üéÖ");

    // –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥–æ–±–∏–≤–∞–µ–º –∞–≤—Ç–æ–ø–ª–µ–π
    audioRef.current?.play().catch((e) => log("autoplay retry: " + String(e)));
  }

  async function attachMic() {
    const pc = pcRef.current!;
    // –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –±–µ–∑ –≤—ã–±–æ—Ä–∞ deviceId
    const constraints: MediaStreamConstraints = {
      audio: {
        channelCount: 1,
        noiseSuppression: true,
        echoCancellation: true,
        autoGainControl: true,
      },
    };
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    const [track] = stream.getAudioTracks();

    // –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –≤ —É–∂–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ-—Ç—Ä–∞–Ω—Å–∏–≤–µ—Ä
    await audioTxRef.current?.sender.replaceTrack(track);

    // –ü—Ä–æ—Å—Ç–æ–π VAD-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä (UX)
    setupSimpleVAD(stream, (talking) => {
      setIsTalking(talking);
      const audio = audioRef.current;
      if (audio) audio.volume = talking ? 0.6 : 1.0; // –º—è–≥–∫–æ –ø—Ä–∏–≥–ª—É—à–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –∫–æ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏–º
    });
  }

  function hangup() {
    dcRef.current?.close();
    pcRef.current?.getSenders().forEach((s) => s.track?.stop());
    pcRef.current?.close();
    pcRef.current = null;
    setStarted(false);
    log("–ó–≤–æ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.");
  }

  // UI helpers
  const statusText = started ? (isTalking ? "–í—ã –≥–æ–≤–æ—Ä–∏—Ç–µ‚Ä¶" : "–í—ã–∑–æ–≤ –∞–∫—Ç–∏–≤–µ–Ω") : "–ì–æ—Ç–æ–≤ –∫ –∑–≤–æ–Ω–∫—É";
  const statusDot = started ? (isTalking ? "bg-green-500" : "bg-emerald-500") : "bg-gray-400";

  return (
      <main className="min-h-screen bg-gradient-to-b from-sky-50 to-white flex items-center justify-center p-6">
        <div className="w-[360px]">
          {/* "–¢—Ä—É–±–∫–∞" */}
          <div className="rounded-[2rem] shadow-xl bg-white border border-gray-100 overflow-hidden">
            {/* –®–∞–ø–∫–∞ –∫–æ–Ω—Ç–∞–∫—Ç–∞ */}
            <div className="p-6 flex flex-col items-center text-center">
              <div className="relative">
                <div className={`absolute -top-1 -right-1 w-3.5 h-3.5 rounded-full ring-2 ring-white ${statusDot}`} />
                <Image
                    src="/santa.png"
                    alt="Santa Claus"
                    width={112}
                    height={112}
                    className="rounded-full object-cover border-4 border-white shadow-md"
                    priority
                />
              </div>

              <div className="mt-4">
                <div className="text-lg font-semibold">Santa Claus</div>
                <div className="text-xs text-gray-500">–°–µ–≤–µ—Ä–Ω—ã–π –ø–æ–ª—é—Å ‚Ä¢ –ö–æ–Ω—Ç–∞–∫—Ç—ã</div>
              </div>

              <div className="mt-4 flex items-center gap-2 text-sm">
                <span className={`inline-block w-2 h-2 rounded-full ${statusDot}`} />
                <span className="text-gray-600">{statusText}</span>
              </div>
            </div>

            {/* –ü–∞–Ω–µ–ª—å –¥–µ–π—Å—Ç–≤–∏–π –∫–∞–∫ –≤ —Ç–µ–ª–µ—Ñ–æ–Ω–µ */}
            <div className="px-6 pb-2">
              <div className="flex items-center justify-center gap-6 py-5">
                {!started ? (
                    <button
                        onClick={startCall}
                        className="h-14 w-14 rounded-full bg-green-500 text-white flex items-center justify-center shadow-md active:scale-95 transition"
                        aria-label="–ü–æ–∑–≤–æ–Ω–∏—Ç—å"
                        title="–ü–æ–∑–≤–æ–Ω–∏—Ç—å"
                    >
                      {/* handset icon */}
                      <svg xmlns="http://www.w3.org/2000/svg" className="h-7 w-7" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M6.62 10.79a15.05 15.05 0 006.59 6.59l2.2-2.2a1 1 0 011.02-.24c1.12.37 2.33.57 3.57.57a1 1 0 011 1V21a1 1 0 01-1 1C10.85 22 2 13.15 2 2a1 1 0 011-1h3.49a1 1 0 011 1c0 1.24.2 2.45.57 3.57a1 1 0 01-.24 1.02l-2.2 2.2z" />
                      </svg>
                    </button>
                ) : (
                    <button
                        onClick={hangup}
                        className="h-14 w-14 rounded-full bg-red-500 text-white flex items-center justify-center shadow-md active:scale-95 transition"
                        aria-label="–ó–∞–≤–µ—Ä—à–∏—Ç—å"
                        title="–ó–∞–≤–µ—Ä—à–∏—Ç—å"
                    >
                      {/* handset down icon */}
                      <svg xmlns="http://www.w3.org/2000/svg" className="h-7 w-7 rotate-135" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M21 16a1 1 0 01-1 1c-1.24 0-2.45-.2-3.57-.57a1 1 0 00-1.02.24l-2.2 2.2a15.05 15.05 0 01-6.59-6.59l2.2-2.2a1 1 0 00.24-1.02A12.58 12.58 0 008 4a1 1 0 00-1-1H4a1 1 0 00-1 1C3 13.15 11.85 22 22 22a1 1 0 001-1v-3.49a1 1 0 00-1-1z" />
                      </svg>
                    </button>
                )}
              </div>

              {/* –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ä–µ—á–∏ */}
              <div className="pb-5 flex items-center justify-center gap-2 text-xs text-gray-500">
                <span className={`inline-flex h-2.5 w-2.5 rounded-full ${isTalking ? "bg-green-500 animate-pulse" : "bg-gray-300"}`} />
                <span>{isTalking ? "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–µ–Ω" : "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∂–¥—ë—Ç"}</span>
              </div>
            </div>
          </div>

          {/* –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –ª–æ–≥–∞ */}
          <div className="flex items-center justify-between mt-3">
            <button
                className="text-xs text-gray-500 underline underline-offset-4"
                onClick={() => setShowLogs((s) => !s)}
            >
              {showLogs ? "–°–∫—Ä—ã—Ç—å –ª–æ–≥" : "–ü–æ–∫–∞–∑–∞—Ç—å –ª–æ–≥"}
            </button>
          </div>

          {showLogs && (
              <div className="mt-2 h-48 overflow-auto border rounded-xl p-2 text-xs bg-white/80 shadow-inner">
                {logs.map((l, i) => (
                    <div key={i} className="whitespace-pre-wrap">
                      {new Date(l.t).toLocaleTimeString()} ‚Äî {l.text}
                    </div>
                ))}
              </div>
          )}
        </div>

        {/* –ê—É–¥–∏–æ-—ç–ª–µ–º–µ–Ω—Ç */}
        <audio ref={audioRef} autoPlay playsInline />
      </main>
  );
}

/** –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ICE-—Å–±–æ—Ä–∫–∏, —á—Ç–æ–±—ã SDP –≤–∫–ª—é—á–∞–ª –∫–∞–Ω–¥–∏–¥–∞—Ç—ã */
async function waitForIceGatheringComplete(pc: RTCPeerConnection) {
  if (pc.iceGatheringState === "complete") return;
  await new Promise<void>((resolve) => {
    function check() {
      if (pc.iceGatheringState === "complete") {
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    }
    pc.addEventListener("icegatheringstatechange", check);
  });
}

/**
 * –ü—Ä–æ—Å—Ç–µ–π—à–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è RMS ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏/UX.
 * –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –±–∞—Ä–¥–∂-–∏–Ω–∞ –æ–ø–∏—Ä–∞–µ–º—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–Ω—É—é VAD Realtime.
 */
function setupSimpleVAD(stream: MediaStream, onState: (talking: boolean) => void) {
  const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
  const ctx = new AudioCtx();
  const src = ctx.createMediaStreamSource(stream);
  const analyser = ctx.createAnalyser();
  analyser.fftSize = 1024;
  src.connect(analyser);
  const data = new Uint8Array(analyser.fftSize);

  let talking = false;
  function tick() {
    analyser.getByteTimeDomainData(data);
    let sum = 0;
    for (let i = 0; i < data.length; i++) {
      const v = (data[i] - 128) / 128;
      sum += v * v;
    }
    const rms = Math.sqrt(sum / data.length);
    const nowTalking = rms > 0.03;
    if (nowTalking !== talking) {
      talking = nowTalking;
      onState(talking);
    }
    requestAnimationFrame(tick);
  }
  tick();
}
