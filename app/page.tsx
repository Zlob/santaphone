// app/page.tsx
"use client";

import React, { useEffect, useRef, useState } from "react";
import { santaSystemPrompt } from "@/lib/santaPrompt";

type LogLine = { t: number; text: string };

export default function Home() {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const dcRef = useRef<RTCDataChannel | null>(null);
  const [started, setStarted] = useState(false);
  const [logs, setLogs] = useState<LogLine[]>([]);
  const [voice, setVoice] = useState("ash");
  const [model, setModel] = useState("gpt-realtime-mini");
  const [micDeviceId, setMicDeviceId] = useState<string | undefined>(undefined);
  const [mics, setMics] = useState<MediaDeviceInfo[]>([]);
  const [isTalking, setIsTalking] = useState(false);

  function log(text: string) {
    setLogs((prev) => [...prev, { t: Date.now(), text }]);
  }

  useEffect(() => {
    // –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–≤
    navigator.mediaDevices.enumerateDevices().then((devices) => {
      setMics(devices.filter((d) => d.kind === "audioinput"));
    });
  }, []);

  async function startCall() {
    if (started) return;

    log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC‚Ä¶");

    const pc = new RTCPeerConnection({
      iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }],
    });
    pcRef.current = pc;

    // DataChannel (–Ω–∞ —Å–ª—É—á–∞–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–∞–Ω–¥/–Ω–∞—Å—Ç—Ä–æ–µ–∫)
    const dc = pc.createDataChannel("santa-data");
    dcRef.current = dc;
    dc.onopen = () => {
      // 1) —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (–ø—Ä–æ–º–ø—Ç)
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          instructions: santaSystemPrompt,     // <-- —Ä—É—Å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
          voice,                               // "alloy" –∏ —Ç.–ø.
          modalities: ["audio","text"],
          turn_detection: { type: "server_vad" }
          // –í–ê–ñ–ù–û: –ù–ï –ø–µ—Ä–µ–¥–∞—ë–º –∑–¥–µ—Å—å model
        }
      }));

      // 2) —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –î–µ–¥ –ú–æ—Ä–æ–∑ —Å–∞–º –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª—Å—è —Å—Ä–∞–∑—É:
      dc.send(JSON.stringify({
        type: "response.create",
        response: {
          conversation: "auto",
          modalities: ["audio","text"],
          instructions: "–°–∫–∞–∂–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ 10‚Äì15 —Å–µ–∫—É–Ω–¥ –∏ —Å–ø—Ä–æ—Å–∏ –∏–º—è —Ä–µ–±—ë–Ω–∫–∞.",
        }
      }));
    };
    dc.onmessage = (e) => log(`DC: ${e.data}`);

    // –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ (–≥–æ–ª–æ—Å –î–µ–¥–∞ –ú–æ—Ä–æ–∑–∞)
    pc.ontrack = (event) => {
      const [stream] = event.streams;
      if (audioRef.current) {
        audioRef.current.srcObject = stream;
        audioRef.current.play().catch(() => {});
      }
    };

    // –ú–∏–∫—Ä–æ—Ñ–æ–Ω
    const constraints: MediaStreamConstraints = {
      audio: {
        deviceId: micDeviceId ? { exact: micDeviceId } : undefined,
        channelCount: 1,
        noiseSuppression: true,
        echoCancellation: true,
        autoGainControl: true,
      },
    };
    const mic = await navigator.mediaDevices.getUserMedia(constraints);
    mic.getTracks().forEach((t) => pc.addTrack(t, mic));

    // –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ—á–∏ (–ø—Ä–æ—Å—Ç–æ–π): –º–µ–Ω—è–µ–º —Ñ–ª–∞–≥ isTalking
    setupSimpleVAD(mic, (talking) => {
      setIsTalking(talking);
      // –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ ¬´–º—è–≥–∫–æ –∑–∞–≥–ª—É—à–∞—Ç—å¬ª —É–¥–∞–ª—ë–Ω–Ω–æ–µ –∞—É–¥–∏–æ,
      // –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥–æ–≤–æ—Ä–∏–ª, —á—Ç–æ–±—ã —É—Å–∏–ª–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç –±–∞—Ä–¥–∂-–∏–Ω–∞:
      const audio = audioRef.current;
      if (audio) audio.volume = talking ? 0.3 : 1.0;
    });

    // –ü–æ–ª—É—á–∞–µ–º —É–¥–∞–ª—ë–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã ICE
    pc.onicecandidate = () => {
      // –í —Ä–µ–∂–∏–º–µ HTTP-SDP –æ–±–º–µ–Ω–∞ –æ–±—ã—á–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –≤—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è –≤ SDP,
      // —Ç–∞–∫ —á—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Å—ã–ª–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚Äî –æ—Å—Ç–∞–≤–∏–º –ø—É—Å—Ç—ã–º.
    };

    // –°–æ–∑–¥–∞—ë–º –æ—Ñ—Ñ–µ—Ä
    const offer = await pc.createOffer({
      offerToReceiveAudio: true,
      offerToReceiveVideo: false,
    });
    await pc.setLocalDescription(offer);

    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ñ—Ñ–µ—Ä –Ω–∞ —Å–≤–æ–π —Å–µ—Ä–≤–µ—Ä ‚Äî –æ–Ω –æ–±–º–µ–Ω—è–µ—Ç—Å—è —Å OpenAI –∏ –≤–µ—Ä–Ω—ë—Ç answer
    const resp = await fetch("/api/sdp", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        sdp: offer.sdp,
        voice,
        model,
      }),
    });

    if (!resp.ok) {
      const err = await resp.json().catch(() => ({}));
      log(`–û—à–∏–±–∫–∞ SDP: ${err?.error || resp.statusText}`);
      return;
    }

    const answerSdp = await resp.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

    setStarted(true);
    log("–ì–æ—Ç–æ–≤–æ! –ì–æ–≤–æ—Ä–∏ —Å –î–µ–¥–æ–º –ú–æ—Ä–æ–∑–æ–º üéÖ");
  }

  function hangup() {
    dcRef.current?.close();
    pcRef.current?.getSenders().forEach((s) => s.track?.stop());
    pcRef.current?.close();
    pcRef.current = null;
    setStarted(false);
    log("–ó–≤–æ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.");
  }

  return (
    <main className="min-h-screen p-6 mx-auto max-w-2xl">
      <h1 className="text-2xl font-bold mb-4">–î–µ–¥ –ú–æ—Ä–æ–∑ ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∑–≤–æ–Ω–æ–∫ (MVP)</h1>

      <div className="space-y-3 mb-6">
        <div>
          <label className="block text-sm font-medium mb-1">–ú–∏–∫—Ä–æ—Ñ–æ–Ω</label>
          <select
            className="border rounded p-2 w-full"
            value={micDeviceId || ""}
            onChange={(e) => setMicDeviceId(e.target.value || undefined)}
            disabled={started}
          >
            <option value="">–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é</option>
            {mics.map((d) => (
              <option key={d.deviceId} value={d.deviceId}>{d.label || d.deviceId}</option>
            ))}
          </select>
        </div>

        <div className="grid grid-cols-2 gap-3">
          <div>
            <label className="block text-sm font-medium mb-1">–ì–æ–ª–æ—Å</label>
            <select
              className="border rounded p-2 w-full"
              value={voice}
              onChange={(e) => setVoice(e.target.value)}
              disabled={started}
            >
              <option value="ash">Ash</option>
              <option value="verse">Verse</option>
              <option value="cove">Cove</option>
              {/* –î–æ–±–∞–≤—å –≤–∞—Ä–∏–∞–Ω—Ç—ã –≥–æ–ª–æ—Å–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤ —Ç–≤–æ—ë–º –∞–∫–∫–∞—É–Ω—Ç–µ */}
            </select>
          </div>
          <div>
            <label className="block text-sm font-medium mb-1">–ú–æ–¥–µ–ª—å</label>
            <input
              className="border rounded p-2 w-full"
              value={model}
              onChange={(e) => setModel(e.target.value)}
              disabled={started}
            />
          </div>
        </div>

        <div className="flex items-center gap-3">
          {!started ? (
            <button
              onClick={startCall}
              className="px-4 py-2 rounded bg-blue-600 text-white"
            >
              –ü–æ–∑–≤–æ–Ω–∏—Ç—å –î–µ–¥—É –ú–æ—Ä–æ–∑—É
            </button>
          ) : (
            <button
              onClick={hangup}
              className="px-4 py-2 rounded bg-gray-700 text-white"
            >
              –ó–∞–≤–µ—Ä—à–∏—Ç—å
            </button>
          )}
          <div className={`text-sm px-2 py-1 rounded ${isTalking ? "bg-green-200" : "bg-gray-200"}`}>
            {isTalking ? "–í—ã –≥–æ–≤–æ—Ä–∏—Ç–µ‚Ä¶" : "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –∂–¥—ë—Ç"}
          </div>
        </div>
      </div>

      <audio ref={audioRef} autoPlay playsInline />

      <div className="mt-6">
        <h2 className="font-semibold mb-2">–õ–æ–≥</h2>
        <div className="h-56 overflow-auto border rounded p-2 text-sm bg-white">
          {logs.map((l, i) => (
            <div key={i} className="whitespace-pre-wrap">{new Date(l.t).toLocaleTimeString()} ‚Äî {l.text}</div>
          ))}
        </div>
      </div>
    </main>
  );
}

/**
 * –ü—Ä–æ—Å—Ç–µ–π—à–∏–π VAD –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è RMS ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏/UX.
 * –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –±–∞—Ä–¥–∂-–∏–Ω–∞ –æ–ø–∏—Ä–∞–µ–º—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–Ω—É—é VAD Realtime.
 */
function setupSimpleVAD(stream: MediaStream, onState: (talking: boolean) => void) {
  const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
  const ctx = new AudioCtx();
  const src = ctx.createMediaStreamSource(stream);
  const analyser = ctx.createAnalyser();
  analyser.fftSize = 1024;
  src.connect(analyser);
  const data = new Uint8Array(analyser.fftSize);

  let talking = false;
  function tick() {
    analyser.getByteTimeDomainData(data);
    let sum = 0;
    for (let i = 0; i < data.length; i++) {
      const v = (data[i] - 128) / 128;
      sum += v * v;
    }
    const rms = Math.sqrt(sum / data.length);
    const nowTalking = rms > 0.03; // –ø—Ä–æ—Å—Ç–µ–π—à–∏–π –ø–æ—Ä–æ–≥
    if (nowTalking !== talking) {
      talking = nowTalking;
      onState(talking);
    }
    requestAnimationFrame(tick);
  }
  tick();
}
